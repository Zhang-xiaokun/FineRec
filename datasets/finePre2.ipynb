{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FineRec preprocess 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_num:  12391\n",
      "train_seq_num & user_num:  12373\n",
      "test_seq_num:  12311\n",
      "#interactions:  110313\n",
      "sequence average length:  8.915622726905358\n",
      "dataset:  Yelp\n",
      "2023-12-29 08:51:17\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "meta_dataset = 'Yelp'\n",
    "data_path =  './dict/' + meta_dataset + '/session_data.csv'\n",
    "\n",
    "if meta_dataset == 'Beauty':\n",
    "    # 'Brand','Ingredients','Effectiveness','Scent','Price','Color','Size'\n",
    "    attr_list = ['Brand','Ingredients','Effectiveness','Scent','Price','Color','Size', 'Compatibility', 'Longevity']\n",
    "elif meta_dataset == 'Cell_Phones_and_Accessories':\n",
    "    # Brand, Performance, color, Battery ,Connectivity,Price, Size\n",
    "    attr_list = ['Brand', 'Performance', 'Color', 'Battery' ,'Connectivity','Price', 'Size']\n",
    "elif meta_dataset == 'Sports_and_Outdoors':\n",
    "    # Price, Quality, Functionality,Size,Protection,Material,Comfort\n",
    "    attr_list = ['Price', 'Quality', 'Functionality', 'Size', 'Protection', 'Material', 'Comfort']\n",
    "elif meta_dataset == 'Yelp':\n",
    "    # Price, Brand, Quality, Material, Size, Appearance, Washability, Functionality, Style, Durability,\n",
    "    attr_list = ['Price', 'Food', 'Location', 'Ambience', 'Service', 'Cleanliness', 'Parking']\n",
    "\n",
    "data_all = pd.read_csv(data_path)\n",
    "if meta_dataset == 'Beauty' or meta_dataset == 'Home_and_Kitchen':\n",
    "    data_all = data_all.reset_index()[['sessionID', 'itemID', attr_list[0], attr_list[1],attr_list[2],attr_list[3],attr_list[4],attr_list[5],attr_list[6],attr_list[7],attr_list[8]]]\n",
    "else:\n",
    "    data_all = data_all.reset_index()[['sessionID', 'itemID', attr_list[0], attr_list[1],attr_list[2],attr_list[3],attr_list[4],attr_list[5],attr_list[6]]]\n",
    "\n",
    "attr_num = len(attr_list)\n",
    "\n",
    "# recorde all items\n",
    "# dict {sessionID:[itemID,itemID]} \n",
    "sess_all = {}\n",
    "#  dict {sessionID:[opinID,opinID]}\n",
    "attr1_all = {}\n",
    "attr2_all = {}\n",
    "attr3_all = {}\n",
    "attr4_all = {}\n",
    "attr5_all = {}\n",
    "attr6_all = {}\n",
    "attr7_all = {}\n",
    "attr8_all = {}\n",
    "attr9_all = {}\n",
    "\n",
    "item_count = 0\n",
    "user_count = 0\n",
    "inter_count = 0\n",
    "\n",
    "for _, row in data_all.iterrows():\n",
    "    sess_id = row['sessionID']\n",
    "    item_id = row['itemID']\n",
    "    attr1_opin = row[attr_list[0]]\n",
    "    attr2_opin = row[attr_list[1]]\n",
    "    attr3_opin = row[attr_list[2]]\n",
    "    attr4_opin = row[attr_list[3]]\n",
    "    attr5_opin = row[attr_list[4]]\n",
    "    attr6_opin = row[attr_list[5]]\n",
    "    attr7_opin = row[attr_list[6]]\n",
    "    if meta_dataset == 'Beauty' or meta_dataset == 'Home_and_Kitchen':\n",
    "        attr8_opin = row[attr_list[7]]\n",
    "        attr9_opin = row[attr_list[8]]\n",
    "    if sess_id in sess_all:\n",
    "        sess_all[sess_id].append(item_id)\n",
    "        attr1_all[sess_id].append(attr1_opin)\n",
    "        attr2_all[sess_id].append(attr2_opin)\n",
    "        attr3_all[sess_id].append(attr3_opin)\n",
    "        attr4_all[sess_id].append(attr4_opin)\n",
    "        attr5_all[sess_id].append(attr5_opin)\n",
    "        attr6_all[sess_id].append(attr6_opin)\n",
    "        attr7_all[sess_id].append(attr7_opin)\n",
    "        if meta_dataset == 'Beauty' or meta_dataset == 'Home_and_Kitchen':\n",
    "            attr8_all[sess_id].append(attr8_opin)\n",
    "            attr9_all[sess_id].append(attr9_opin)\n",
    "    else:\n",
    "        sess_all[sess_id] = []\n",
    "        sess_all[sess_id].append(item_id)\n",
    "        attr1_all[sess_id] = []\n",
    "        attr1_all[sess_id].append(attr1_opin)\n",
    "        attr2_all[sess_id] = []\n",
    "        attr2_all[sess_id].append(attr2_opin)\n",
    "        attr3_all[sess_id] = []\n",
    "        attr3_all[sess_id].append(attr3_opin)\n",
    "        attr4_all[sess_id] = []\n",
    "        attr4_all[sess_id].append(attr4_opin)\n",
    "        attr5_all[sess_id] = []\n",
    "        attr5_all[sess_id].append(attr5_opin)\n",
    "        attr6_all[sess_id] = []\n",
    "        attr6_all[sess_id].append(attr6_opin)\n",
    "        attr7_all[sess_id] = []\n",
    "        attr7_all[sess_id].append(attr7_opin)\n",
    "        if meta_dataset == 'Beauty' or meta_dataset == 'Home_and_Kitchen':\n",
    "            attr8_all[sess_id] = []\n",
    "            attr9_all[sess_id] = []\n",
    "            attr8_all[sess_id].append(attr8_opin)\n",
    "            attr9_all[sess_id].append(attr9_opin)\n",
    "\n",
    "# 限制每个seq长度\n",
    "for sess_temp in sess_all.keys():\n",
    "    seq = sess_all[sess_temp]\n",
    "    if len(seq) >20:\n",
    "        sess_all[sess_temp] = seq[-20:]\n",
    "        attr1_all[sess_id] = attr1_all[sess_id][-20:]\n",
    "        attr2_all[sess_id] = attr2_all[sess_id][-20:]\n",
    "        attr3_all[sess_id] = attr3_all[sess_id][-20:]\n",
    "        attr4_all[sess_id] = attr4_all[sess_id][-20:]\n",
    "        attr5_all[sess_id] = attr5_all[sess_id][-20:]\n",
    "        attr6_all[sess_id] = attr6_all[sess_id][-20:]\n",
    "        attr7_all[sess_id] = attr7_all[sess_id][-20:]\n",
    "        if meta_dataset == 'Beauty' or meta_dataset == 'Home_and_Kitchen':\n",
    "            attr8_all[sess_id] = attr8_all[sess_id][-20:]\n",
    "            attr9_all[sess_id] = attr9_all[sess_id][-20:]\n",
    "\n",
    "# 形成train set\n",
    "# 统计 train set 出现的item，给item重新编号\n",
    "item_num = 1\n",
    "# dict{lod_itemID:new_itemID}\n",
    "item_dict = {}\n",
    "# train_set [[u_id ...], [x_t-1...], [label...]\n",
    "tra = [[],[],[]]\n",
    "# dict {train_sessionID:[itemID,itemID]}  去掉了seq中last item(不包含test的label)， 也可以调整为去掉两个item\n",
    "train_sess = {}\n",
    "\n",
    "# dict {item_id:[user_id, user_id]}\n",
    "train_items = {}\n",
    "\n",
    "# dict {item_id:opin_id}\n",
    "attr1_item_opin = {}\n",
    "attr2_item_opin = {}\n",
    "attr3_item_opin = {}\n",
    "attr4_item_opin = {}\n",
    "attr5_item_opin = {}\n",
    "attr6_item_opin = {}\n",
    "attr7_item_opin = {}\n",
    "attr8_item_opin = {}\n",
    "attr9_item_opin = {}\n",
    "\n",
    "\n",
    "for sess_temp in sess_all.keys():\n",
    "    all_seqs = sess_all[sess_temp]\n",
    "    train_seqs_t = all_seqs[:-1]\n",
    "    a1_opin = attr1_all[sess_temp][:-1]\n",
    "    a2_opin = attr2_all[sess_temp][:-1]\n",
    "    a3_opin = attr3_all[sess_temp][:-1]\n",
    "    a4_opin = attr4_all[sess_temp][:-1]\n",
    "    a5_opin = attr5_all[sess_temp][:-1]\n",
    "    a6_opin = attr6_all[sess_temp][:-1]\n",
    "    a7_opin = attr7_all[sess_temp][:-1]\n",
    "    if meta_dataset == 'Beauty' or meta_dataset == 'Home_and_Kitchen':\n",
    "        a8_opin = attr8_all[sess_temp][:-1]\n",
    "        a9_opin = attr9_all[sess_temp][:-1]\n",
    "    else:\n",
    "        a8_opin = attr6_all[sess_temp][:-1]\n",
    "        a9_opin = attr7_all[sess_temp][:-1]\n",
    "    inter_count += len(train_seqs_t)\n",
    "#     item_seq with new ID\n",
    "    new_seq = []\n",
    "    for x, a1, a2, a3, a4, a5, a6, a7, a8, a9 in zip(train_seqs_t, a1_opin, a2_opin,a3_opin,a4_opin,a5_opin,a6_opin,a7_opin,a8_opin,a9_opin):\n",
    "        if x in item_dict:\n",
    "            new_seq.append(item_dict[x])\n",
    "            if sess_temp not in train_items[item_dict[x]]:\n",
    "                train_items[item_dict[x]].append(sess_temp)\n",
    "                attr1_item_opin[item_dict[x]].append(a1)\n",
    "                attr2_item_opin[item_dict[x]].append(a2)\n",
    "                attr3_item_opin[item_dict[x]].append(a3)\n",
    "                attr4_item_opin[item_dict[x]].append(a4)\n",
    "                attr5_item_opin[item_dict[x]].append(a5)\n",
    "                attr6_item_opin[item_dict[x]].append(a6)\n",
    "                attr7_item_opin[item_dict[x]].append(a7)\n",
    "                if meta_dataset == 'Beauty' or meta_dataset == 'Home_and_Kitchen':\n",
    "                    attr8_item_opin[item_dict[x]].append(a8)\n",
    "                    attr9_item_opin[item_dict[x]].append(a9)\n",
    "        else:\n",
    "            item_dict[x] = item_num\n",
    "            new_seq.append(item_num)\n",
    "            \n",
    "            train_items[item_num] = [] \n",
    "            train_items[item_num].append(sess_temp)\n",
    "            attr1_item_opin[item_num] = []\n",
    "            attr2_item_opin[item_num] = []\n",
    "            attr3_item_opin[item_num] = []\n",
    "            attr4_item_opin[item_num] = []\n",
    "            attr5_item_opin[item_num] = []\n",
    "            attr6_item_opin[item_num] = []\n",
    "            attr7_item_opin[item_num] = []\n",
    "            \n",
    "            attr1_item_opin[item_num].append(a1)\n",
    "            attr2_item_opin[item_num].append(a2)\n",
    "            attr3_item_opin[item_num].append(a3)\n",
    "            attr4_item_opin[item_num].append(a4)\n",
    "            attr5_item_opin[item_num].append(a5)\n",
    "            attr6_item_opin[item_num].append(a6)\n",
    "            attr7_item_opin[item_num].append(a7)\n",
    "            if meta_dataset == 'Beauty' or meta_dataset == 'Home_and_Kitchen':\n",
    "                attr8_item_opin[item_num] = []\n",
    "                attr9_item_opin[item_num] = []\n",
    "                attr8_item_opin[item_num].append(a8)\n",
    "                attr9_item_opin[item_num].append(a9)\n",
    "            \n",
    "            item_num += 1\n",
    "    train_sess[sess_temp] = new_seq\n",
    "    tra[0].append(sess_temp)\n",
    "#     预测时考虑last item\n",
    "    tra[1].append(new_seq[:-1])\n",
    "    tra[2].append(new_seq[-1])\n",
    "    \n",
    "item_count =  item_num-1\n",
    "user_count = len(tra[0])\n",
    "\n",
    "fre_item_mat = np.zeros((item_count, item_count), dtype=int)\n",
    "# 全部的共现关系Original \n",
    "for sess in train_sess.keys():\n",
    "    item_seq = np.unique(train_sess[sess])\n",
    "    for it1 in item_seq:\n",
    "        for it2 in item_seq:\n",
    "            if it1 != it2:\n",
    "#                 print(sess)\n",
    "                fre_item_mat[int(it1)-1, int(it2)-1] +=1 \n",
    "                \n",
    "fre_user_mat = np.zeros((user_count, user_count), dtype=int)\n",
    "# 全部的共现关系Original \n",
    "for item_t in train_items.keys():\n",
    "    user_seq = np.unique(train_items[item_t])\n",
    "    for it1 in user_seq:\n",
    "        for it2 in user_seq:\n",
    "            if it1 != it2:\n",
    "                fre_user_mat[int(it1)-1, int(it2)-1] +=1 \n",
    "\n",
    "# building user_fre & item_fre csr_matrix\n",
    "def spar_graph(fre_mat):\n",
    "    indices = [] # 非0元素的列坐标，item_id -1\n",
    "    all_data = [] # 非0元素值，opin_id\n",
    "    indptr = [0] # i i-1 行非0元素个数，0-0， n-总共元素个数，行数+1\n",
    "    for i_list in fre_mat:\n",
    "        i_temp_list = np.nonzero(i_list)[0].tolist()\n",
    "#         if len(i_temp_list) == 0:\n",
    "#             non_co += 1\n",
    "        indices += i_temp_list\n",
    "        all_data += [1]*len(i_temp_list)\n",
    "        indptr.append(indptr[-1]+len(i_temp_list))\n",
    "#     print('item without co-occurren: ',str(non_co))\n",
    "    # indptr:session长度累加和; indices:item_id 减1, 由每个session内item组成; data:item在session内的权重，全部为1.\n",
    "    coo_mat = (all_data, indices, indptr)\n",
    "    return coo_mat\n",
    "\n",
    "item_co_mat = spar_graph(fre_item_mat)\n",
    "user_co_mat = spar_graph(fre_user_mat)\n",
    "\n",
    "\n",
    "# test_set [[u_id ...], [x_t-1...], [label...]\n",
    "tes = [[],[],[]]\n",
    "tes_seq_num = 0\n",
    "for sess_temp in sess_all.keys():\n",
    "    all_seqs = sess_all[sess_temp]\n",
    "    if all_seqs[-1] in item_dict:\n",
    "        tes_seq_num += 1\n",
    "        new_seq = []\n",
    "        for x in all_seqs:\n",
    "            new_seq.append(item_dict[x])\n",
    "        tes[0].append(sess_temp)\n",
    "    #     预测时考虑last item\n",
    "        tes[1].append(new_seq[:-1])\n",
    "        tes[2].append(item_dict[all_seqs[-1]])\n",
    "    \n",
    "\n",
    "print('item_num: ',str(item_count))\n",
    "print('train_seq_num & user_num: ',str(user_count))\n",
    "print('test_seq_num: ',str(tes_seq_num))\n",
    "\n",
    "inter_count += tes_seq_num\n",
    "\n",
    "def spar_matrix(tra_seq):\n",
    "    indices = [] # 非0元素的列坐标，item_id -1\n",
    "    all_data = [] # 非0元素值，opin_id\n",
    "    indptr = [0] # i i-1 行非0元素个数，0-0， n-总共元素个数，行数+1\n",
    "    for sess_temp in tra_seq.keys():\n",
    "        it_list = tra_seq[sess_temp]\n",
    "        it_index = np.unique(it_list) - 1\n",
    "        indices += (it_index).tolist()\n",
    "        all_data += [1]*len(it_index)\n",
    "        indptr.append(indptr[-1] + len(it_index.tolist()))\n",
    "    results = (all_data, indices, indptr)\n",
    "    return results\n",
    "\n",
    "ui_co_mat = spar_matrix(train_sess)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 返回 [[u1,u2],[attr1_opin, attr1_opin]]\n",
    "def formulate_seq(dict_ui, dict_op):\n",
    "    results = [[],[]]\n",
    "    temp_res = [[],[]]\n",
    "    max_len =0\n",
    "    for x in dict_ui.keys():\n",
    "        seqs_id = dict_ui[x]\n",
    "        opin_id = dict_op[x]\n",
    "        new_us_seq = []\n",
    "        new_op_seq = []\n",
    "        for id_t, op_t in zip(seqs_id, opin_id):\n",
    "            if op_t != 0 and id_t not in new_us_seq:\n",
    "                new_us_seq.append(id_t)\n",
    "                new_op_seq.append(op_t)\n",
    "        if len(new_us_seq)==0:\n",
    "            new_us_seq.append(0)\n",
    "            new_op_seq.append(0)\n",
    "        if len(new_us_seq)>max_len:\n",
    "            max_len = len(new_us_seq)\n",
    "        temp_res[0].append(new_us_seq)\n",
    "        temp_res[1].append(new_op_seq)\n",
    "    for ui_seq, op_seq in zip(temp_res[0],temp_res[1]):\n",
    "        pad_len = max_len - len(ui_seq)\n",
    "        pad_ui_seq = ui_seq + [0]*pad_len\n",
    "        pad_op_seq = op_seq + [0]*pad_len\n",
    "        results[0].append(pad_ui_seq)\n",
    "        results[1].append(pad_op_seq)\n",
    "#     print('max_len:',str(max_len))\n",
    "    return results\n",
    "\n",
    "# u_seq = {1:[1,2,3,1],2:[4,5], 3:[7,8,9]}\n",
    "# u_op = {1:[45,56,0,45],2:[66,0], 3:[0,33,0]}\n",
    "# # [[[1,2],[4],[8]],[[45,56],[66],[33]]]\n",
    "# formulate_seq(u_seq,u_op)\n",
    "\n",
    "ui_1 = formulate_seq(train_sess,attr1_all)\n",
    "ui_2 = formulate_seq(train_sess,attr2_all)\n",
    "ui_3 = formulate_seq(train_sess,attr3_all)\n",
    "ui_4 = formulate_seq(train_sess,attr4_all)\n",
    "ui_5 = formulate_seq(train_sess,attr5_all)\n",
    "ui_6 = formulate_seq(train_sess,attr6_all)\n",
    "ui_7 = formulate_seq(train_sess,attr7_all)\n",
    "iu_1 = formulate_seq(train_items,attr1_item_opin)\n",
    "iu_2 = formulate_seq(train_items,attr2_item_opin)\n",
    "iu_3 = formulate_seq(train_items,attr3_item_opin)\n",
    "iu_4 = formulate_seq(train_items,attr4_item_opin)\n",
    "iu_5 = formulate_seq(train_items,attr5_item_opin)\n",
    "iu_6 = formulate_seq(train_items,attr6_item_opin)\n",
    "iu_7 = formulate_seq(train_items,attr7_item_opin)\n",
    "\n",
    "if meta_dataset == 'Beauty' or meta_dataset == 'Home_and_Kitchen':\n",
    "    ui_8 = formulate_seq(train_sess,attr8_all)\n",
    "    ui_9 = formulate_seq(train_sess,attr9_all)\n",
    "    iu_8 = formulate_seq(train_items,attr8_item_opin)\n",
    "    iu_9 = formulate_seq(train_items,attr9_item_opin)\n",
    "\n",
    "def ui_seq(dict_ui):\n",
    "    results = []\n",
    "    temp_res = []\n",
    "    max_len =0\n",
    "    for x in dict_ui.keys():\n",
    "        seqs_id = dict_ui[x]\n",
    "        if len(seqs_id)>max_len:\n",
    "            max_len = len(seqs_id)\n",
    "        temp_res.append(seqs_id)\n",
    "    for temp_l in temp_res:\n",
    "        pad_len = max_len - len(temp_l)\n",
    "        pad_ui_seq = temp_l + [0]*pad_len\n",
    "        results.append(pad_ui_seq)\n",
    "    return results\n",
    "\n",
    "ui_list = ui_seq(train_sess)\n",
    "iu_list = ui_seq(train_items)\n",
    "\n",
    "print('#interactions: ',inter_count)\n",
    "\n",
    "print('sequence average length: ', (inter_count)/(user_count) * 1.0)\n",
    "# print('cold sequence average length: ', (all_train+all_tes_nocold+all_tes_cold)/(len(tra_seqs) + len(tes_seqs_nocold) +len(tes_seqs_cold) * 1.0))\n",
    "train_data_path = './datasets/' + meta_dataset\n",
    "\n",
    "if not os.path.exists(train_data_path):\n",
    "    os.makedirs(train_data_path)\n",
    "path_data_train = train_data_path + \"/train.txt\"\n",
    "path_normal_test = train_data_path + \"/test.txt\"\n",
    "\n",
    "tra_save = (tra[0], tra[1], tra[2],item_co_mat,user_co_mat, ui_list, iu_list, ui_1, ui_2, ui_3, ui_4, ui_5, ui_6, ui_7, iu_1, iu_2, iu_3, iu_4, iu_5, iu_6, iu_7)\n",
    "tes_save = (tes[0], tes[1], tes[2])\n",
    "\n",
    "if meta_dataset == 'Beauty' or meta_dataset == 'Home_and_Kitchen':\n",
    "    tra_save = (tra[0], tra[1], tra[2],item_co_mat,user_co_mat, ui_list, iu_list, ui_1, ui_2, ui_3, ui_4, ui_5, ui_6, ui_7,ui_8, ui_9, iu_1, iu_2, iu_3, iu_4, iu_5, iu_6, iu_7, iu_8, iu_9)\n",
    "\n",
    "pickle.dump(tra_save, open(path_data_train, 'wb'))\n",
    "pickle.dump(tes_save, open(path_normal_test, 'wb'))\n",
    "print(\"dataset: \", meta_dataset)\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
